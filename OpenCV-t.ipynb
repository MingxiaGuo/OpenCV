{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MingxiaGuo/Artifical_Intelligence/blob/main/OpenCV_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2jjjm2dv4IHT"
   },
   "source": [
    "# OpenCV\n",
    "\n",
    "[Documentation](https://docs.opencv.org/4.x/index.html)\n",
    "\n",
    "* Install OpenCV and imutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X2fxA4lp-3u2"
   },
   "source": [
    "## Install OpenCV and imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KAxFA8bi39C1",
    "outputId": "a3104092-f9ea-4aeb-ca28-12b1e0d1d477"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-contrib-python in /Users/gmx/anaconda3/lib/python3.11/site-packages (4.8.0.76)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /Users/gmx/anaconda3/lib/python3.11/site-packages (from opencv-contrib-python) (1.24.3)\n",
      "Requirement already satisfied: imutils in /Users/gmx/anaconda3/lib/python3.11/site-packages (0.5.4)\n"
     ]
    }
   ],
   "source": [
    "# pip list\n",
    "!pip install opencv-python==3.4.1.15 # 安装python版的opencv, 3.4.2以后有些算法有专利权限问题导致用不了\n",
    "!pip install opencv-contrib-python==3.4.1.15 # opencv的拓展，如一些特征提取的算法\n",
    "\n",
    "!pip install imutils #Install image processing tools, https://github.com/jrosebr1/imutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and displaying an image\n",
    "\n",
    "All images consist of pixels which are the raw building blocks of images. Images are made of pixels in a grid. A 640 x 480 image has 640 columns (the width) and 480 rows (the height). There are 640 * 480 = 307200 pixels in an image with those dimensions.\n",
    "\n",
    "Each pixel in a grayscale image has a value representing the shade of gray. In OpenCV, there are 256 shades of gray — from 0 to 255. So a grayscale image would have a grayscale value associated with each pixel.\n",
    "\n",
    "Pixels in a color image have additional information. There are several color spaces that you’ll soon become familiar with as you learn about image processing. For simplicity let’s only consider the RGB color space.\n",
    "\n",
    "In OpenCV color images in the RGB (Red, Green, Blue) color space have a 3-tuple associated with each pixel: (B, G, R) .\n",
    "\n",
    "Notice the ordering is BGR rather than RGB. This is because when OpenCV was first being developed many years ago the standard was BGR ordering. Over the years, the standard has now become RGB but OpenCV still maintains this “legacy” BGR ordering to ensure no existing code breaks.\n",
    "\n",
    "Each value in the BGR 3-tuple has a range of [0, 255] . How many color possibilities are there for each pixel in an RGB image in OpenCV? That’s easy: 256 * 256 * 256 = 16777216 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "40LtSKZE-xcl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "width=1011, height=1409, depth=3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "import imutils\n",
    "import cv2\n",
    "# load the input image and show its dimensions, keeping in mind that\n",
    "# images are represented as a multi-dimensional NumPy array with\n",
    "# shape no. rows (height) x no. columns (width) x no. channels (depth)\n",
    "# We describe matrices by # of rows x # of columns, The number of rows is our height, And the number of columns is our width\n",
    "# Depth is the number of channels — in our case this is three since we’re working with 3 color channels: Blue, Green, and Red\n",
    "image = cv2.imread(\"TITANIC.JPG\")\n",
    "(h, w, d) = image.shape\n",
    "print(\"width={}, height={}, depth={}\".format(w, h, d))\n",
    "# display the image to our screen -- we will need to click the window\n",
    "# open by OpenCV and press a key on our keyboard to continue execution\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing individual pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R=187, G=207, B=182\n"
     ]
    }
   ],
   "source": [
    "# access the RGB pixel located at x=50, y=100, keepind in mind that\n",
    "# OpenCV stores images in BGR order rather than RGB\n",
    "(B, G, R) = image[100, 50]\n",
    "print(\"R={}, G={}, B={}\".format(R, G, B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Array slicing and cropping\n",
    "\n",
    "Extracting “regions of interest” (ROIs) is an important skill for image processing.\n",
    "\n",
    "Say, for example, you’re working on recognizing faces in a movie. First, you’d run a face detection algorithm to find the coordinates of faces in all the frames you’re working with. Then you’d want to extract the face ROIs and either save them or process them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract a 150x150 pixel square ROI (Region of Interest) from the\n",
    "# input image starting at x=500,y=400 at ending at x=650,y=550\n",
    "roi = image[400:550, 500:650] # image[startY:endY, startX:endX]\n",
    "cv2.imshow(\"ROI\", roi)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoothing an image\n",
    "\n",
    "In many image processing pipelines, we must blur an image to reduce high-frequency noise, making it easier for our algorithms to detect and understand the actual contents of the image rather than just noise that will “confuse” our algorithms. Blurring an image is very easy in OpenCV and there are a number of ways to accomplish it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply a Gaussian blur with a 11x11 kernel to the image to smooth it,\n",
    "# useful when reducing high frequency noise\n",
    "blurred = cv2.GaussianBlur(image, (11, 11), 0)\n",
    "cv2.imshow(\"Blurred\", blurred)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing on an image\n",
    "\n",
    "We’re going to draw a rectangle, circle, and line on an input image. We’ll also overlay text on an image as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw a 2px thick red rectangle surrounding the face\n",
    "output = image.copy()\n",
    "# input image starting at x=500,y=400 at ending at x=650,y=550\n",
    "cv2.rectangle(output, (500, 400), (650, 550), (0, 0, 255), 2) # (500, 400): top-left; (650, 550): bottom-right; (0, 0, 255):线条颜色；2:线条粗细，(a negative value will make a solid rectangle).\n",
    "cv2.imshow(\"Rectangle\", output)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Since we are using OpenCV’s functions rather than NumPy operations \n",
    "# we can supply our coordinates in (x, y) order rather than (y, x) \n",
    "# since we are not manipulating or accessing the NumPy array directly \n",
    "# — OpenCV is taking care of that for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw a blue 20px (filled in) circle on the image centered at\n",
    "# x=300,y=150\n",
    "output = image.copy()\n",
    "cv2.circle(output, (300, 150), 20, (255, 0, 0), -1) # (300, 150)：circle's center coorfinate; 20: circle radius\n",
    "cv2.imshow(\"Circle\", output)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw a 5px thick red line from x=60,y=20 to x=400,y=200\n",
    "output = image.copy()\n",
    "cv2.line(output, (60, 20), (400, 200), (0, 0, 255), 5)\n",
    "cv2.imshow(\"Line\", output)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw green text on the image\n",
    "# available fonts: https://docs.opencv.org/3.4.1/d0/de1/group__core.html#ga0f9314ea6e35f99bb23f29567fc16e11\n",
    "output = image.copy()\n",
    "cv2.putText(output, \"OpenCV + TITANIC!!!\", (10, 25), # (10, 25):start point;\n",
    "\tcv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 5)  # cv2.FONT_HERSHEY_SIMPLEX:font; 0.7: font size;(0, 255, 0): text color; 2: The thickness of the stroke in pixels.\n",
    "cv2.imshow(\"Text\", output)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting objects\n",
    "\n",
    " count the number of Tetris blocks in the following image\n",
    " ![](tetris_blocks.webp)\n",
    "\n",
    "Along the way we’ll be:\n",
    "* Learning how to convert images to grayscale with OpenCV\n",
    "* Performing edge detection\n",
    "* Thresholding a grayscale image\n",
    "* Finding, counting, and drawing contours\n",
    "* Conducting erosion and dilation\n",
    "* Masking an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import argparse # a command line arguments parsing package which comes with all installations of Python.\n",
    "import imutils\n",
    "import cv2\n",
    "# construct the argument parser and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-i\", \"--image\", required=True,\n",
    "\thelp=\"path to input image\")\n",
    "# args = vars(ap.parse_args()) # 命令行执行脚本传参数时使用\n",
    "args = vars(ap.parse_args(['--image', 'tetris_blocks.webp'])) # 用在jupyter中\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge detection\n",
    "\n",
    "Edge detection is useful for finding boundaries of objects in an image — it is effective for segmentation purposes.\n",
    "\n",
    "![](opencv_tetris_edge.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying edge detection we can find the outlines of objects in images\n",
    "# cv2.Canny(img, minVal, maxVal, aperture_size)\n",
    "# aperture_size : The Sobel kernel size. By default this value is 3 and hence is not shown \n",
    "# 30: A minimum threshold, 150: The maximum threshold\n",
    "# Different values for the minimum and maximum thresholds will return different edge maps.\n",
    "edged = cv2.Canny(gray, 30, 150) # Using the popular Canny algorithm (developed by John F. Canny in 1986), we can find the edges in the image.\n",
    "cv2.imshow(\"Edged\", edged)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting and drawing contours\n",
    "\n",
    "![](opencv_tetris_contours.gif)\n",
    "![](opencv_tutorial_object_counting.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find contours (i.e., outlines) of the foreground(white) objects in the thresholded image\n",
    "cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,\n",
    "\tcv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts) # This is very important accounting for the fact that cv2.findContours implementation changed between OpenCV 2.4, OpenCV 3, and OpenCV 4. This compatibility line is present on the blog wherever contours are involved.\n",
    "output = image.copy() # copy of the original image so that we can draw contours\n",
    "# loop over the contours\n",
    "for c in cnts:\n",
    "\t# draw each contour on the output image with a 3px thick purple\n",
    "\t# outline, then display the output contours one at a time\n",
    "\tcv2.drawContours(output, [c], -1, (240, 0, 159), 3) # (240, 0, 159): 紫色\n",
    "\tcv2.imshow(\"Contours\", output)\n",
    "\tcv2.waitKey(0)\n",
    "\t\n",
    "# draw the total number of contours found in purple\n",
    "text = \"I found {} objects!\".format(len(cnts))\n",
    "cv2.putText(output, text, (10, 25),  cv2.FONT_HERSHEY_SIMPLEX, 0.7,\n",
    "\t(240, 0, 159), 2)\n",
    "cv2.imshow(\"Contours\", output)\n",
    "cv2.waitKey(0)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masking and bitwise operations\n",
    "\n",
    "Masks allow us to “mask out” regions of an image we are uninterested in. We call them “masks” because they will hide regions of images we do not care about.\n",
    "\n",
    "![](opencv_tutorial_tetris_bitwise_masking.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a typical operation we may want to apply is to take our mask and\n",
    "# apply a bitwise AND to our input image, keeping only the masked\n",
    "# regions\n",
    "mask = thresh.copy()\n",
    "output = cv2.bitwise_and(image, image, mask=mask)\n",
    "cv2.imshow(\"Output\", output)\n",
    "cv2.waitKey(0)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMeNnL83KPhvIBPwrGwe6ZH",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
